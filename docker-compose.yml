# My homelab docker setup
version: "3.9"

services:
  # Dashboard
  dashy:
    container_name: "dashy"
    image: "lissy93/dashy:latest"
    ports:
      - "80:80"
    volumes:
      - ./dashy/config.yml:/app/public/conf.yml
    restart: always

  # Neworking 
  pihole:
    container_name: "pihole"
    image: "pihole/pihole:latest"
    ports:
      - "53:53/tcp"
      - "53:53/udp"
      - "2001:80/tcp"
      # - "67:67/udp" # Only required if you are using Pi-hole as your DHCP server
    environment:
      TZ: "America/Denver"
      PIHOLE_DNS_: "127.0.0.1#53;9.9.9.9;149.112.112.112;8.8.8.8"
      DNSSEC: "true"
      WEB_PORT: "80"
      WEB_BIND_ADDR: "0.0.0.0"
    volumes:
      - "./pihole/etc-pihole:/etc/pihole"
      - "./pihole/etc-dnsmasq.d:/etc/dnsmasq.d"
    restart: always
  # pialert:
    # container_name: "pialert"
    # image: "jokobsk/pi.alert:latest"      
    # privileged: true
    # network_mode: "host"  
    # volumes:
      # - ./pialert/config:/home/pi/pialert/config
      # - ./pialert/db:/home/pi/pialert/db
      # (optional) useful for debugging if you have issues setting up the container
      # - local/path/logs:/home/pi/pialert/front/log
    # environment:
      # TZ: "America/Denver"
      # HOST_USER_ID: "1000"
      # HOST_USER_GID: "1000"
      # PORT: "2002"
    # restart: always
  smokeping:
    image: "lscr.io/linuxserver/smokeping:latest"
    container_name: "smokeping"
    ports:
      - "2003:80"
    environment:
      PUID: "1000"
      PGID: "1000"
      TZ: "America/Denver"
    volumes:
      - "./smokeping/config:/config"
      - "./smokeping/data:/data"
    restart: always
  zero-tier:
    image: "zerotier/zerotier:latest"
    container_name: "zerotier-one"
    ports:
      - "2004:9993"
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun
    environment:
      ZEROTIER_API_SECRET: "Q2HxUecWTLSP2ZeIkledm83T43uyHgSE"
    restart: always
  cloudflare:
    image: "cloudflare/cloudflared:latest"
    container_name: "cloudflare"
    command: "tunnel --no-autoupdate run --token eyJhIjoiMWJmNzkyMTAzNDBlYTNiMGMwY2ExZDg2YWNkZDZhZTgiLCJ0IjoiMGYzYzU3YzAtZDM3NC00ZDIxLWEwN2MtMDVlN2FkZGVmNzNkIiwicyI6Ik5EQmxObVF4TkdZdE5EYzBNeTAwTUdNMkxUazNaREl0TmpneE4yVXpOV0pqWVdJMiJ9"
    restart: always
    
  # Media
  plex:
    container_name: "plex"
    image: "linuxserver/plex"
    network_mode: "host"
    environment:
      VERSION: "docker"
      PATH: "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin" 
      #CUDA_VERSION: "10.0.130"
      #CUDA_PKG_VERSION: "10-0=10.0.130-1"
      #LD_LIBRARY_PATH: "/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64"
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "all"
      #NVIDIA_REQUIRE_CUDA: "cuda>=10.0 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=410,driver<411"
      TZ: "US/MST"
    volumes:
      - "/share/CE_CACHEDEV1_DATA/.qpkg/NVIDIA_GPU_DRV/usr:/usr/local/nvidia:rw"
      - "/dev/shm:/transcode" # RAM transcoding?!
      - "/mnt/plex:/media"
    # devices:
      # - "/dev/nvidia0:/dev/nvidia0"
      # - "/dev/nvidiactl:/dev/nvidiactl"
      # - "/dev/nvidia-uvm:/dev/nvidia-uvm"
    restart: always
  transmission:
    image: "lscr.io/linuxserver/transmission:latest"
    container_name: "transmission"
    environment:
      PUID: "1000"
      PGID: "1000"
      TZ: "US/MST"
      #TRANSMISSION_WEB_HOME= #optional
      #USER= #optional
      #PASS= #optional
      #WHITELIST= #optional
      #PEERPORT= #optional
      #HOST_WHITELIST= #optional
    volumes:
      - ./transmission/config:/config
      - ./transmission/watch:/watch
      - /mnt/plex:/downloads # Path to hard drives
    ports:
      - "9091:9091"
      - "51413:51413"
      - "51413:51413/udp"
    restart: always
  tautulli:
    image: "ghcr.io/tautulli/tautulli"
    container_name: "tautulli"
    volumes:
      - "./tautulli/config:/config"
    environment:
      PUID: "1000"
      PGID: "1000"
      TZ: "US/MST"
    ports:
      - "4001:8181"
    restart: always
  radarr:
    image: lscr.io/linuxserver/radarr:latest
    container_name: radarr
    environment:
      PUID: "1000"
      PGID: "1000"
      TZ: "US/MST"
    volumes:
      - ./radarr/config:/config
      - /mnt/plex:/movies #optional
    ports:
      - "4002:7878"
    restart: always
  mullvad:
    image: "yacht7/openvpn-client"
    container_name: "openvpn-client"
    cap_add:
        - NET_ADMIN
    environment: 
      KILL_SWITCH: "on"                         # Turns off internet access if the VPN connection drops
      FORWARDED_PORTS: "51820"                   # NUMBER TO REMEMBER FROM BEFORE, READ STEP 7 under STEP 1 (THIS IS CONFUSING AS IM TYPING IT, BUT READ IT)
      SUBNETS: "192.168.0.0/24,192.168.1.0/24"  # Allows for the service to be accessed through LAN
    devices:
      - "/dev/net/tun"                      
    volumes:
      - ./mullvad:/data/vpn   
      # File unzipped before from Mullvad, it's location. Make sure to keep the ":/data/vpn" part at the end
    ports:
      - "5665:5665"                         # Opening port for to access hypothetical Transmission container that would be routing through this VPN
      #- "1500:1500"                         # Opening port for other application routing through VPN
    restart: always
  
  # System maintance
  watchtower:
    container_name: "watchtower"
    image: "containrrr/watchtower"
    volumes: 
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      WATCHTOWER_CLEANUP: "true"
      TZ: "US/MST"
      WATCHTOWER_REVIVE_STOPPED: "true"
    restart: always
  registry: # My own docker registry
    container_name: "registry"
    image: "registry:2"
    ports:
      - "5001:5000"
    restart: always
  glances:
    container_name: "glances"
    image: "nicolargo/glances:latest"
    ports:
      - "5002:61208"
    pid: host
    environment:
      GLANCES_OPT: "-w --disable-webui --fahrenheit"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "./glances/glances.conf:/glances/conf/glances.conf" 
    restart: always
  # portainer:
  #   container_name: "portainer"
  #   image: "portainer/portainer-ce:latest"
  #   ports:
  #     - "5003:8000"
  #     - "5004:9443" 
  #   volumes:
  #     - ./portainer:/data 
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   restart: always
    
  # Searxng
  searx_caddy:
    container_name: searxng_caddy
    image: caddy:2-alpine
    network_mode: host
    volumes:
      - ./searxng/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - ./searxng/caddy/caddy-data:/data:rw
      - ./searxng/caddy/caddy-config:/config:rw
    environment:
      - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-http://localhost:80}
      - SEARXNG_TLS=${LETSENCRYPT_EMAIL:-internal}
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
      - DAC_OVERRIDE

  searxng_redis:
    container_name: searxng_redis
    image: "redis:alpine"
    command: redis-server --save "" --appendonly "no"
    networks:
      - searxng
    tmpfs:
      - /var/lib/redis
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE

  searxng:
    container_name: searxng
    image: searxng/searxng:latest
    networks:
      - searxng
    ports:
     - "8080:8080"
    volumes:
      - ./searxng/searxng:/etc/searxng:rw
      #- ./searx-extras-by-me/searxng.png:/usr/local/searxng/searx/static/themes/simple/img/searxng.png
      #- ./searx-extras-by-me/searxng.svg:/usr/local/searxng/searx/static/themes/simple/img/searxng.svg
      #- ./searx-extras-by-me/searx/engines/chatgpt.py:/usr/local/searxng/searx/engines/chatgpt.py
    environment:
      - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

networks:
  searxng:
    ipam:
      driver: default

volumes:
  caddy-data:
